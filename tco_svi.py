# -*- coding: utf-8 -*-
"""Tco-SVI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12rmfK4N_aJ2jrSTWj4oS5nL5gDQD62Kw
"""

import requests
import pandas as pd

# Replace with your personal Mapillary API token
MAPILLARY_TOKEN = "MLY|24480959524925279|9f5be238cc5324b5024ca30d4b2688bb"

# Bounding box for Trincomalee town (adjust if needed)
# [min_lon, min_lat, max_lon, max_lat]
bbox =[81.1847, 8.5337, 81.2422, 8.6302]
url = f"https://graph.mapillary.com/images?access_token={MAPILLARY_TOKEN}&fields=id,thumb_1024_url,geometry&bbox={','.join(map(str, bbox))}"

response = requests.get(url)
data = response.json()

records = []
for feature in data.get("data", []):
    img_id = feature["id"]
    lon, lat = feature["geometry"]["coordinates"]
    url = feature["thumb_1024_url"]
    records.append([img_id, url, lat, lon])

df = pd.DataFrame(records, columns=["id", "url", "lat", "lon"])
df.to_csv("svi_trinco.csv", index=False)

print(df.head())

import os
import requests
from tqdm import tqdm

df = pd.read_csv("svi_trinco.csv")

os.makedirs("mapillary_images", exist_ok=True)

for idx, row in tqdm(df.iterrows(), total=len(df)):
    img_url = row["url"]
    img_path = f"mapillary_images/{row['id']}.jpg"
    try:
        r = requests.get(img_url, stream=True)
        if r.status_code == 200:
            with open(img_path, "wb") as f:
                for chunk in r:
                    f.write(chunk)
            df.loc[idx, "filepath"] = img_path
    except:
        print(f"Failed {img_url}")

df.to_csv("svi_trinco.csv", index=False)

# ===============================
# 1Ô∏è‚É£ Install Required Libraries
# ===============================
!pip install geopandas folium osmnx segmentation-models-pytorch torch torchvision albumentations rasterio shapely geemap

# ===============================
# 2Ô∏è‚É£ Import Libraries
# ===============================
import os
import cv2
import torch
import numpy as np
import pandas as pd
import folium
import matplotlib.pyplot as plt

from torchvision import transforms
from scipy.stats import entropy
import torchvision.models.segmentation as models
import geemap, ee

!pip install geemap
import geemap
import ee
# ===============================
# 3Ô∏è‚É£ Initialize Google Earth Engine (optional)
# ===============================
ee.Authenticate()
ee.Initialize(project='ee-lavibas23')

# ===============================
# 4Ô∏è‚É£ Load SVI CSV
# ===============================
svi_df = pd.read_csv("svi_trinco.csv")  # path to your CSV
svi_df.head()

# ===============================
# 5Ô∏è‚É£ Setup Device & Model
# ===============================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# Load pretrained DeepLabV3 (ResNet50 backbone)
model = models.deeplabv3_resnet50(pretrained=True).to(device)
model.eval()

# Image preprocessing
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((512, 512)),
    transforms.ToTensor()
])

# ===============================
# 6Ô∏è‚É£ Define COCO Classes for Segmentation
# ===============================
COCO_LABELS = {
    2: "building",
    3: "road",
    21: "vegetation",
    23: "sky"
}

# ===============================
# 7Ô∏è‚É£ Segmentation Function
# ===============================
def segment_image(img_path):
    img = cv2.imread(img_path)[:,:,::-1]  # BGR ‚Üí RGB
    inp = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(inp)['out'][0]
    pred = torch.argmax(output, dim=0).cpu().numpy()

    # Pixel proportions
    h, w = pred.shape
    total = h * w
    props = {label: (pred == idx).sum() / total for idx, label in COCO_LABELS.items()}

    return props

# Test one image
print(segment_image(svi_df.filepath.iloc[0]))

# ===============================
# 8Ô∏è‚É£ Compute Entropy & Livability Index
# ===============================
def compute_indices(props):
    # Shannon entropy of features
    values = np.array(list(props.values()))
    morph_entropy = entropy(values + 1e-9, base=2)

    # Simple livability formula
    greenery = props.get("vegetation", 0)
    sky = props.get("sky", 0)
    road = props.get("road", 0)
    building = props.get("building", 0)

    livability = (0.5*greenery + 0.3*sky + 0.2*road) - (0.2*building)

    return morph_entropy, livability

# ===============================
# 9Ô∏è‚É£ Process All Images
# ===============================
results = []
for _, row in svi_df.iterrows():
    props = segment_image(row.filepath)
    entropy_val, livability_val = compute_indices(props)
    results.append([row.id, row.lat, row.lon, entropy_val, livability_val])

res_df = pd.DataFrame(results, columns=["id","lat","lon","entropy","livability"])
res_df.to_csv("svi_trinco_results.csv", index=False)
res_df.head()

# ===============================
# üîü Visualize Results on Folium Map
# ===============================
m = folium.Map(location=[svi_df.lat.mean(), svi_df.lon.mean()], zoom_start=13)

for _, row in res_df.iterrows():
    folium.CircleMarker(
        location=[row.lat, row.lon],
        radius=6,
        fill=True,
        color="blue",
        fill_color="blue",
        fill_opacity=0.6,
        popup=f"Entropy: {row.entropy:.2f}, Livability: {row.livability:.2f}"
    ).add_to(m)

m

# Displays interactive map in Colab

# ===============================
# 1Ô∏è‚É£1Ô∏è‚É£ Optional: Compare with Sentinel-2 NDVI via GEE
# ===============================
Map = geemap.Map(center=[svi_df.lat.mean(), svi_df.lon.mean()], zoom=12)

# Sentinel-2 median image
s2 = ee.ImageCollection("COPERNICUS/S2_SR") \
      .filterBounds(ee.Geometry.Point(svi_df.lon.mean(), svi_df.lat.mean())) \
      .filterDate("2023-01-01","2023-12-31") \
      .median()

ndvi = s2.normalizedDifference(['B8','B4']).rename('NDVI')
Map.addLayer(ndvi, {'min':0, 'max':1, 'palette':['white','green']}, "NDVI")
Map

import torch
import cv2
from torchvision import transforms
import torchvision.models.segmentation as models
import numpy as np

# Device and model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = models.deeplabv3_resnet50(pretrained=True).to(device)
model.eval()

# Preprocessing
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Load one image
img_path = "mapillary_images/1001133405266595.jpg"
img = cv2.imread(img_path)[:,:,::-1]  # BGR -> RGB
inp = transform(img).unsqueeze(0).to(device)

with torch.no_grad():
    output = model(inp)['out'][0]  # shape [num_classes, H, W]

pred = torch.argmax(output, dim=0).cpu().numpy()

# Check which class indices appear in prediction
unique_classes = np.unique(pred)
print("Unique class indices in this image:", unique_classes)

# ===============================
# 1Ô∏è‚É£ Install Required Libraries
# ===============================
!pip install segmentation-models-pytorch torch torchvision albumentations opencv-python tqdm

# ===============================
# 2Ô∏è‚É£ Import Libraries
# ===============================
import os
import cv2
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
import albumentations as A
from segmentation_models_pytorch import Unet

from scipy.stats import entropy

# ===============================
# 3Ô∏è‚É£ Load Your CSV
# ===============================
svi_df = pd.read_csv("svi_trinco.csv")  # your SVI CSV with filepaths
svi_df.head()

# ===============================
# 4Ô∏è‚É£ Setup Device
# ===============================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# ===============================
# 5Ô∏è‚É£ Load Pretrained Segmentation Model
# ===============================
# Here we use Unet with resnet34 backbone pretrained on ADE20K (urban scenes)
model = Unet(encoder_name="resnet34", encoder_weights="imagenet", classes=4, activation=None)
# classes=4: building, road, vegetation, sky (example)
model.to(device)
model.eval()

# Note: For actual pretrained Mapillary Vistas weights, you would load weights from a checkpoint

# ===============================
# 6Ô∏è‚É£ Define Image Preprocessing
# ===============================
transform = A.Compose([
    A.Resize(512, 512),
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
])

# ===============================
# 7Ô∏è‚É£ Segmentation Function
# ===============================
# Map class indices to labels
CLASS_LABELS = {0: "building", 1: "road", 2: "vegetation", 3: "sky"}

def segment_image(img_path):
    img = cv2.imread(img_path)[:,:,::-1]  # BGR -> RGB
    augmented = transform(image=img)
    img_tensor = torch.tensor(augmented["image"].transpose(2,0,1), dtype=torch.float32).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(img_tensor)  # shape: [1, classes, H, W]
        pred = torch.argmax(output, dim=1)[0].cpu().numpy()

    # Pixel proportions
    h, w = pred.shape
    total = h * w
    props = {label: (pred == idx).sum()/total for idx, label in CLASS_LABELS.items()}

    # Normalize
    total_prop = sum(props.values())
    if total_prop > 0:
        for k in props:
            props[k] /= total_prop
    else:
        for k in props:
            props[k] = 1e-9

    return props

# ===============================
# 8Ô∏è‚É£ Compute Entropy & Livability
# ===============================
def compute_indices(props):
    values = np.array(list(props.values()))
    values = values / values.sum()

    morph_entropy = entropy(values + 1e-9, base=2)

    greenery = props.get("vegetation", 0)
    sky = props.get("sky", 0)
    road = props.get("road", 0)
    building = props.get("building", 0)

    livability = (0.5*greenery + 0.3*sky + 0.2*road) - (0.2*building)

    return morph_entropy, livability

# ===============================
# 9Ô∏è‚É£ Process All Images
# ===============================
results = []
for _, row in tqdm(svi_df.iterrows(), total=len(svi_df)):
    props = segment_image(row.filepath)
    entropy_val, livability_val = compute_indices(props)
    results.append([row.id, row.lat, row.lon, entropy_val, livability_val])

res_df = pd.DataFrame(results, columns=["id","lat","lon","entropy","livability"])
res_df.to_csv("svi_trinco_results.csv", index=False)
res_df.head()

import folium
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as mcolors
import numpy as np

# ===============================
# 1Ô∏è‚É£ Create Folium Map
# ===============================
center_lat = svi_df.lat.mean()
center_lon = svi_df.lon.mean()
m = folium.Map(location=[center_lat, center_lon], zoom_start=13)

# ===============================
# 2Ô∏è‚É£ Define Color Maps
# ===============================
# Normalize entropy (0‚Äìmax) and livability (-0.2 to 0.8)
entropy_vals = res_df['entropy'].values
livability_vals = res_df['livability'].values

entropy_norm = mcolors.Normalize(vmin=min(entropy_vals), vmax=max(entropy_vals))
livability_norm = mcolors.Normalize(vmin=min(livability_vals), vmax=max(livability_vals))

entropy_cmap = cm.get_cmap('viridis')
livability_cmap = cm.get_cmap('YlGn')

# ===============================
# 3Ô∏è‚É£ Add Circle Markers
# ===============================
for _, row in res_df.iterrows():
    # Color by entropy
    e_color = mcolors.to_hex(entropy_cmap(entropy_norm(row.entropy)))
    # Size by livability (optional scaling)
    size = max(4, row.livability*20 + 6)  # ensure positive radius

    folium.CircleMarker(
        location=[row.lat, row.lon],
        radius=size,
        fill=True,
        color=e_color,
        fill_color=e_color,
        fill_opacity=0.7,
        popup=f"Entropy: {row.entropy:.2f}<br>Livability: {row.livability:.2f}"
    ).add_to(m)

# ===============================
# 4Ô∏è‚É£ Display Map
# ===============================
m

import folium
from folium.plugins import MarkerCluster
import matplotlib.cm as cm
import matplotlib.colors as mcolors
import numpy as np
from branca.colormap import linear, LinearColormap

# ===============================
# 1Ô∏è‚É£ Base Map
# ===============================
m = folium.Map(location=[center_lat, center_lon], zoom_start=13)

folium.TileLayer('Stamen Terrain', name='Terrain', attr='Map tiles by Stamen Design').add_to(m)
folium.TileLayer('CartoDB Positron', name='Light Map', attr='Map tiles by CartoDB').add_to(m)
folium.TileLayer('Esri.WorldImagery', name='Satellite', attr='Tiles ¬© Esri').add_to(m)

# ===============================
# 2Ô∏è‚É£ Normalize
# ===============================
entropy_vals = res_df['entropy'].values
livability_vals = res_df['livability'].values

entropy_norm = mcolors.Normalize(vmin=min(entropy_vals), vmax=max(entropy_vals))
livability_norm = mcolors.Normalize(vmin=min(livability_vals), vmax=max(livability_vals))

entropy_cmap = cm.get_cmap('viridis')
livability_cmap = cm.get_cmap('YlGn')

# ===============================
# 3Ô∏è‚É£ Marker Cluster
# ===============================
marker_cluster = MarkerCluster().add_to(m)

for _, row in res_df.iterrows():
    e_color = mcolors.to_hex(entropy_cmap(entropy_norm(row.entropy)))
    size = max(4, row.livability*20 + 6)

    folium.CircleMarker(
        location=[row.lat, row.lon],
        radius=size,
        fill=True,
        color=e_color,
        fill_color=e_color,
        fill_opacity=0.7,
        popup=f"Entropy: {row.entropy:.2f}<br>Livability: {row.livability:.2f}"
    ).add_to(marker_cluster)

# ===============================
# 4Ô∏è‚É£ Add Legends (working version)
# ===============================
# Entropy colormap
entropy_colormap = LinearColormap(['blue','green','yellow'], vmin=min(entropy_vals), vmax=max(entropy_vals))
entropy_colormap.caption = 'Streetscape Entropy'
entropy_colormap.add_to(m)

# Livability colormap
livability_colormap = LinearColormap(['red','orange','green'], vmin=min(livability_vals), vmax=max(livability_vals))
livability_colormap.caption = 'Livability Index'
livability_colormap.add_to(m)

# ===============================
# 5Ô∏è‚É£ Layer Control
# ===============================
folium.LayerControl().add_to(m)

# ===============================
# 6Ô∏è‚É£ Display Map
# ===============================
m

import folium
import matplotlib.cm as cm
import matplotlib.colors as mcolors
import numpy as np
from branca.colormap import LinearColormap
from folium import IFrame
from folium.plugins import FloatImage

# ===============================
# 1Ô∏è‚É£ Base Map
# ===============================
center_lat = res_df.lat.mean()
center_lon = res_df.lon.mean()

m = folium.Map(location=[center_lat, center_lon], zoom_start=13)

# Add satellite + terrain layers
folium.TileLayer('Stamen Terrain', name='Terrain', attr='Map tiles by Stamen Design').add_to(m)
folium.TileLayer('CartoDB Positron', name='Light Map', attr='Map tiles by CartoDB').add_to(m)
folium.TileLayer('Esri.WorldImagery', name='Satellite', attr='Tiles ¬© Esri').add_to(m)

# ===============================
# 2Ô∏è‚É£ Normalize & colormap
# ===============================
entropy_vals = res_df['entropy'].values
livability_vals = res_df['livability'].values

entropy_norm = mcolors.Normalize(vmin=min(entropy_vals), vmax=max(entropy_vals))
livability_norm = mcolors.Normalize(vmin=min(livability_vals), vmax=max(livability_vals))

entropy_cmap = cm.get_cmap('viridis')
livability_cmap = cm.get_cmap('YlGn')

# ===============================
# 3Ô∏è‚É£ Add markers (no clustering)
# ===============================
for _, row in res_df.iterrows():
    color = mcolors.to_hex(entropy_cmap(entropy_norm(row.entropy)))
    radius = max(4, row.livability * 20 + 6)

    popup_text = f"<b>Entropy:</b> {row.entropy:.2f}<br><b>Livability:</b> {row.livability:.2f}"
    folium.CircleMarker(
        location=[row.lat, row.lon],
        radius=radius,
        color=color,
        fill=True,
        fill_color=color,
        fill_opacity=0.7,
        popup=popup_text
    ).add_to(m)

# ===============================
# 4Ô∏è‚É£ Legends
# ===============================
from branca.element import MacroElement
from jinja2 import Template

# Create custom circle size legend for livability
# Entropy legend
entropy_colormap = LinearColormap(['blue','green','yellow'], vmin=min(entropy_vals), vmax=max(entropy_vals))
entropy_colormap.caption = 'Streetscape Entropy'
entropy_colormap.add_to(m)

size_legend = """
{% macro html(this, kwargs) %}
<div style="position: fixed;
            bottom: 50px; right: 50px; width: 160px; height: 120px;
            background-color: white; z-index:9999; font-size:14px;
            border:2px solid grey; border-radius:5px; padding:10px;">
<b>Livability</b><br>
&nbsp;Low <i style="background:transparent; border:2px solid black; width:6px; height:6px; border-radius:50%; display:inline-block"></i><br>
&nbsp;Medium <i style="background:transparent; border:2px solid black; width:12px; height:12px; border-radius:50%; display:inline-block"></i><br>
&nbsp;High <i style="background:transparent; border:2px solid black; width:20px; height:20px; border-radius:50%; display:inline-block"></i>
</div>
{% endmacro %}
"""

macro = MacroElement()
macro._template = Template(size_legend)
m.get_root().add_child(macro)


# ===============================
# 5Ô∏è‚É£ Add title
# ===============================
title_html = '''
     <h3 align="center" style="font-size:20px"><b>Entropy-Based Streetscape & Livability Map: Trincomalee</b></h3>
     '''
m.get_root().html.add_child(folium.Element(title_html))

# ===============================
# 6Ô∏è‚É£ Layer control
# ===============================
folium.LayerControl().add_to(m)

# ===============================
# 7Ô∏è‚É£ Display map
# ===============================
m